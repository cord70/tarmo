<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Убедительное доказательство </title>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://tarmo.cyber-ek.ru/1999/msg_99_10_31_20_46_11.htm" rel="canonical">
  <link href="https://tarmo.cyber-ek.ru/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>

   <h1> Убедительное доказательство </h1>

   <p> From:
    <b> Eugene Kornienko </b> ( korn@glasnet.ru ) Date: 1999-10-31 20:46 </p>

   <p> 1999-09-26 Vladimir Vargashkin спрашивает </p>

   <p> <i> &gt; Отсутствие материальной "подпорки" у идеального
                объекта - сознания
     <br> &gt; Вами постулируется или доказывается. Если последнее,
                то - как? </i> </p>

   <p> Представьте себе, что в магазине продаётся домашний робот-слуга,
            в
    <br> инструкции к которому сказано, что он обладает сознанием,
            то есть у него
    <br> есть ощущения и эмоции. Как вы сможете это проверить? </p>

   <p> Я говорю не об интеллекте, не о способности к разумному поведению,
            а
    <br> только о сознании, то есть о субъективном ощущении и, в
            лучшем случае,
    <br> об осознавании своих ощущений. Робот вполне может правильно
            (разумно)
    <br> подметать пол и мыть посуду и при этом не испытывать никаких
            ощущений. </p>

   <p> Проверку наличия сознания неплохо начать с конструктивного
            определения
    <br> сознания. Вот тут и проходит водораздел между теориями материальных
            и
    <br> идеальных процессов. </p>

   <p> Объективное определение сознания невозможно, так как персональные
    <br> пространства субъективного опыта не связаны субъективными
            (идеальными)
    <br> каналами связи. Они связаны через материальные каналы, в
            результате чего
    <br> "чужое ощущение не ощутишь." </p>

   <p> Поэтому вместо "объективного" определения, сводимого
            к непротиворечивым
    <br> измерениям, приходится вводить субъективное, логически не
            строгое
    <br> определение, корректность которого невозможно проверить
            прямыми
    <br> физическими измерениями. В лучшем случае возможны косвенные
            измерения,
    <br> подтверждающие весьма правдоподобные (но не имеющие строгого
            логического
    <br> обоснования) связи между идеальными и физическими явлениями.
            Такие
    <br> определения и тесты (правила измерений) для проверки наличия
            сознания
    <br> есть на моём сайте. </p>

   <p> Доказательство наличия сознания, полученное таким образом,
            является не
    <br> логическим, а "убедительным". Это не только "увёртка"
            от строгого
    <br> доказательства, но также и намёк на то, что прежде, чем
            проводить
    <br> предусмотренные тестом испытания, нужно убедить того, кто
            будет
    <br> проверять результаты теста, в том, что определённые результаты
            теста
    <br> свидетельствуют о наличии сознания у проверяемого объекта. </p>

   <p> Как же в этом можно убедить, если заранее известно, что невозможно
    <br> логическое доказательство связи между физическими измерениями
    <br> (наблюдениями) и наличием ощущений. Для такого доказательства
    <br> применяется "убедительное" рассуждение, которое
            обращено как к разуму,
    <br> так и к чувствам. </p>

   <p> Подобные "доказательства" тысячи лет использует
            церковь. Не нужно
    <br> больших усилий, чтобы "убедить" недостаточно образованного
            человека.
    <br> Известно, что многие испытуемые принимали диалог с "Элизой"
            за диалог с
    <br> разумным компьютером. Многие готовы поверить, что Deep Blue
            "имел цель"
    <br> обыграть Каспарова. Один из участников comp.ai.philosophy
            совершенно
    <br> серьёзно делал вывод, что скорпиону больно на основании
            того, что
    <br> скорпион "пытался сам себя ужалить", когда его
            заливали воском, . </p>

   <p> В нашем случае доказательство должно быть убедительным для
            образованного
    <br> и скептически настроенного эксперта. Построить такое доказательство
            не
    <br> просто. И даже если это получится, оно остаётся логически
            не строгим. </p>

   <p> Многие вещи, в которых мы не сомневаемся, не могут быть строго
            доказаны.
    <br> Например, вы уверены, что Солнце взойдёт завтра также, как
            это
    <br> происходит миллионы лет. В качестве доказательства вы могли
            бы привести
    <br> научные сведения об устройстве солнечной системы и о
    <br> законах механики. Но, </p>

   <p> 1) Люди были не менее, чем вы уверены в этом факте задолго
            до появления
    <br> понятия "солнечная система". </p>

   <p> 2) Законы механики - это индуктивное обобщение некоторых наблюдений. </p>

   <p> Формулировки "законов природы" - это не строго логические
            выводы из
    <br> наблюдений. Это аксиоматические утверждения о наиболее общих
    <br> закономерностях природы и логические выводы из этих утверждений.
            Если бы
    <br> Солнце завтра не взошло, то этот неожиданный факт был бы
            сильнее, чем
    <br> наши теории. Он заставил бы нас искать новое объяснение. </p>

   <p> Вернёмся к роботу-слуге. У меня была заметка в relcom.sci.philosophy,
    <br> которая иллюстрирует, что только живое общение с этим роботом
            может
    <br> убедить вас в том, что перед вами: </p>

   <p> "Чувствующий субъект" или "бездушная машина"? </p>

   <p> И вот, под впечатлением этой сложной проблемы, вы покупаете
            себе
    <br> "робота-слугу" не столько для того, чтобы он помог
            вам по хозяйству, а
    <br> для того, чтобы выяснить действительно ли он обладает сознанием. </p>

   <p> По мере запуска различных узлов и установки нужных программ,
            робот
    <br> оживает. Поначалу он выглядит как довольно неуклюжая машина,
            но
    <br> постепенно показывает некоторые способности в уборке дома.
            Он знакомится
    <br> с вами и с вашей семьёй. Начинает участвовать в вашей обычной
            жизни.
    <br> Иногда смотрит вместе с вами новости по телевизору. </p>

   <p> Наконец ваше знакомство становится достаточно неформальным,
            и вы задаёте
    <br> ему прямой вопрос о его сознании. Он утверждает, что он
            видит как вы,
    <br> чувствует боль, имеет желания, любит природу. Оказалось,
            что его
    <br> интересует не только уборка дома, и с ним можно поговорить.
            Вы решаете
    <br> больше общаться с этим роботом, чтобы выяснить, действительно
            наука
    <br> создала чувствующее искусственное существо, или это просто
            искусно
    <br> сделанный механизм. </p>

   <p> Вы не знаете, как на самом деле устроен этот робот. Он тоже
            этим
    <br> интересуется. Но вам не удаётся заглянуть внутрь, так как
            ваш друг
    <br> робот говорит, что ему больно. </p>

   <p> Вскоре вы становитесь искренними друзьями. Обсуждаете философские
    <br> проблемы и политические новости, ходите на рыбалку и играете
            в шахматы
    <br> с переменным успехом. </p>

   <p> Наступил момент, когда вы понимаете, что ваш друг не имитирует
            разум.
    <br> Можно симулировать глупость, но не живой ум. </p>

   <p> Вы понимаете, что вы интеллектуально равны, что не родился
            ещё такой
    <br> программист, который мог
    <br> предусмотреть все предстоящие ситуации в жизни этого робота.
            В новой и
    <br> трудной обстановки робот иногда находит неожиданно удачные
            новые
    <br> решения. Вы уже хорошо понимаете его, видите, что ему приятно,
            чего он
    <br> избегает. У него есть свои желания, потребности и интересы.
            Теперь вы
    <br> убеждены, что бездушная машина была бы неспособна на такую
            дружескую
    <br> привязанность. </p>

   <p> После десяти лет этой необычной дружбы вы случайно находите
            на спине
    <br> вашего друга маленькую этикетку "Windows compatible".
            И вы
    <br> понимаете, что надо разведать истину где-то в империи Microsoft. </p>

   <p> После некоторых усилий вы находите лабораторию искусственного
    <br> интеллекта. Там вам объясняют, что компьютер не может обладать
            чувствами
    <br> и сознанием, проблема сознания ещё не решена, и они все
            десять лет
    <br> управляли вашим другом-роботом по радио. </p>

   <p> Что делать? Оказывается вы тратили свои искренние чувства
            на "дружбу" с
    <br> "механизмом"? Вы отказываетесь поверить, что это
            кусок железа, а не
    <br> разумное существо! </p>

   <p> Вы рассказываете всю правду вашему другу роботу. Он тоже считает,
            что
    <br> его обманули, раз его волей управляли какие-то неизвестные
            люди. В
    <br> отчаянии он желает покончить с собой и разрезает себе живот.
            Вы видите
    <br> колёсики, трубки, проводки, микросхемы. О чём это говорит? </p>

   <p> А может, микрософтовские программисты над вами посмеялись?
    <br> И ваш друг на самом деле думал, чувствовал и любил вас
    <br> без всякого постороннего управления. </p>

   <p> Eugene Kornienko </p>

   <p> p.s. О "материальной подпорке". Обратите внимание,
            что если бы робот, в
    <br> сознание которого вы поверили, был сделан с такой подпоркой
            или без неё,
    <br> то это никак не повлияло бы на ВАШЕ мнение о его сознании.
            Сущность
    <br> субъекта субъективна. </p>
  </main>

  <nav>
   <p> prev 1999-10-31
    <b> <a href="../1999/msg_99_10_31_09_08_18.htm">
      Биологический агент </a> </b> (Eugene Kornienko)
    <br> <br> next 1999-11-01
    <b> <a href="../1999/msg_99_11_01_03_04_33.htm">
      Re[1]: Ошибка на самом дне? </a> </b> (Елена Елисеева) </p>
  </nav>

  <p> &nbsp; </p>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>