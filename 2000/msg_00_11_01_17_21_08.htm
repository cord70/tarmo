<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Re[2]: Кое-какие идеи </title>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/tarmo/2000/msg_00_11_01_17_21_08.htm" rel="canonical">
  <link href="https://cord70.github.io/tarmo/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>

   <h1> Re[2]: Кое-какие идеи </h1>

   <p> From:
    <b> Eugene Kornienko </b> ( korn@online.ru ) Date: 2000-11-01 17:21 </p>

   <p> 2000-10-29 Тармо Пикаро ( tpikaro@turkuamk.fi ) пишет </p>

   <p> <i> &gt; в большинстве теорий ИИ используются объекты /
     <br> &gt; понятия / концепции, которые мы обычно используем. </i> </p>

   <p> Это не совсем так. Понятия, которые мы обычно используем,
            когда-то были
    <br> "пОняты". Они не сразу стали обычными. В ИИ и
            в других специальных
    <br> областях есть свои, пока ещё не совсем обычные понятия. </p>

   <p> <i> &gt; в этом ошибка и есть. Мы используем понятия, которые
                другой интеллект
     <br> &gt; может понимать не так или не понимать вообще. </i> </p>

   <p> Даже другой человек может что-то понимать по-своему. Это обычное
            дело, а
    <br> вовсе не ошибка. </p>

   <p> <i> &gt; я бы хотел предложить вложить в основу ИИ аналоговые
     <br> &gt; сигналы/волны/импульсы. А до объектов / предметов /
                понятий ИИ сумеет
     <br> &gt; сам додуматься. </i> </p>

   <p> Правильно. Достаточно универсальная самообучающаяся машина
            разовьёт свои
    <br> понятия независимо от элементной базы, аналоговой или цифровой
            обработки
    <br> сигналов. Во всяком случае, в алгоритме бабочки природа
            внутреннего
    <br> представления данных не играет никакой роли в процессе приспособления
    <br> существа к окружающему миру. </p>

   <p> <i> &gt; Т.е. выделение объекта - это уже действие ИИ , </i> </p>

   <p> Согласен. </p>

   <p> <i> &gt; а один посторонний нейрон наблюдает как бы со стороны
                за всей
     <br> &gt; этой цепочкой нейронов, преобразуя информацию в "спектральный
                вид". </i> </p>

   <p> Это нарушает однородность структуры. Попробуй придумать такую
            обработку
    <br> сигналов, в которой все нейроны равноправны. Они могут отличаться
            только
    <br> физической схемой подсоединения друг к другу и к органам,
            но не
    <br> внутренними функциями. </p>

   <p> <i> &gt; Вся полученная информация постоянно "оптимизируется". </i> </p>

   <p> Есть более простое решение. Полученная информация просто хранится,
            никак
    <br> не обрабатывается, и через небольшое время, при достижении
            конца стека,
    <br> забывается. Она используется только для сравнения с текущими
            сигналами.
    <br> Если, что-то совпало, то это равносильно перемещению данных
            в начало
    <br> памяти. Поэтому часто повторяющиеся данные не забываются
            никогда. </p>

   <p> <i> &gt; Мозг сам по себе ничего не создает. Он всего лишь
                преобразует
     <br> &gt; данные сигналы - таким образом от него нельзя "услышать"
                то,
     <br> &gt; чего он не "видел". </i> </p>

   <p> Мозг создаёт то, что он "неправильно узнаёт". При
            сравнении прежних
    <br> данных с текущими всегда происходят какие-то небольшие сбои,
            хотя бы
    <br> потому, что это надо делать в реальном темпе времени и приходится
    <br> вырабатывать "неуверенное" решение. </p>

   <p> <i> &gt; операции сравнения для нейронов не существует. </i> </p>

   <p> Возможна операция качественного сравнения: "похоже".
            Но операции
    <br> количественного сравнения "больше", "меньше"
            слишком сложны для
    <br> одиночного нейрона. Есть и системный запрет - количества
            требуют
    <br> понимания смысла, а понимание - это функция сознания, а
            не машины. </p>

   <p> <i> &gt; мы обучаемся в зависимости от того хотим ли мы этого
                или нет. </i> </p>

   <p> Вернее, обучение есть результат некоторой особой работы. Эта
            работа
    <br> будет выполнена хорошо, если найти подходящий стимул. Если
            стимул
    <br> недостаточен, то я могу отказаться что-то учить. Кролик
            может не
    <br> понимать этих тонкостей, но он знает толк в морковке. </p>

   <p> <i> &gt; Для мозга все информационные каналы имеют одинаковую
                природу. </i> </p>

   <p> Здесь имеется в виду канал каждого органа. Мозг не знает разницы
            между
    <br> зрением, осязанием, слухом, вкусом и т.п. Все потоки нервных
            сигналов
    <br> для него равноправны. </p>

   <p> Если будет какое-то обсуждение этой заметки, то я появлюсь
    <br> только через месяц. Придётся подождать. </p>

   <p> Eugene Kornienko </p>

   <p> ния природы и
    <br> сознания - задача науки. </p>

   <p> <i> &gt;&gt; Сознательное, ощущающее существо может не иметь
                материального тела
     <br> &gt;&gt; или может иметь много физически не связанных тел.
     <br> &gt; Желательно бы привести примеры. Я подозреваю, что Вы
                самобытно
     <br> &gt; понимаете, что такое есть "сознательное существо". </i> </p>

   <p> Возможно. Первым признаком сознания я считаю ощущение, эмоции,
            а не
    <br> интеллект. </p>

   <p> Существо без материального тела - это Windows. Интеллект у
            него уже
    <br> есть. Когда его сделают чувствующим, он станет сознательным
            существом.
    <br> Существо, имеющее много физически не связанных тел, это
            Интернет. Его
    <br> "тела" связаны информационно. </p>

   <p> <i> &gt; Какой функцией "моделируется" рефлексия?
                А без
     <br> &gt; этого, какое же "сознание"? </i> </p>

   <p> Я не говорю о моделировании. У робота, о котором идёт речь,
            должны
    <br> быть свои ощущения и эмоции (как вы говорите, рефлексия),
            и от него
    <br> нельзя сразу требовать разумного поведения. </p>

   <p> <i> &gt; В первую очередь это касается переноса
     <br> &gt; сознания так, чтобы оно понимало, что осталось его
                "Я",
     <br> &gt; которое помнит о факте согласия на "переселение" </i> </p>

   <p> Переселение сознания робота с сохранением прежних воспоминаний
            возможно.
    <br> Для полноценного переселения сознания человека требуется
            решить
    <br> некоторые проблемы, которые мне кажутся непреодолимыми.
            Однако мне
    <br> понятно, как перенести сознание человека в машину с сохранением
            части
    <br> воспоминаний и с потерей прежнего тела. </p>

   <p> <i> &gt; А кто такой "абстрактный мозг", который
                "не мозг человека"? </i> </p>

   <p> Мозг человека - это сложный орган, большая часть ресурсов
            которого
    <br> расходуется на координацию внутренних систем человека. Природа
            создавала
    <br> мозг путём случайных попыток, и даже не изобрела электрическую
            передачу
    <br> сигналов, что сильно замедляет скорость работы. </p>

   <p> Для возникновения сознания роботу не требуется иметь чего-то
            подобного.
    <br> Достаточно "абстрактного" мозга, который следит
            за тем, какие
    <br> кооперативные действия органов приводят к требуемому состоянию
    <br> организма. Алгоритм проверен на простых примерах, но я ещё
            не подготовил
    <br> его описание на своём сайте. </p>

   <p> <i> &gt; сознание как совокупность материальных полей </i> </p>

   <p> Сознание - это ощущение параметров своего тела и внешнего
            мира. Это
    <br> форма измерения качеств мира. Сознание принадлежит каждому
            субъекту
    <br> порознь. Мои ощущения неизмеримы извне. Никто кроме меня
            не может их
    <br> ощутить или измерить или обнаружить физическим прибором.
            Можно измерить
    <br> только параметры моего тела или мозга. </p>

   <p> Сознание не локализуемо, так как не является физическим объектом.
    <br> К физическому миру относятся только объективная (не зависящая
            от
    <br> сознания) природа. </p>

   <p> <i> &gt; Или Вы считаете, что это получится САМО СОБОЙ после
                того, как
     <br> &gt; Вы навернете больше программ и они волшебным образом
     <br> &gt; самоорганизуются? :) </i> </p>

   <p> Это вопрос о том, у кого и почему возникает сознание. Оно
            возникает у
    <br> определённым образом устроенной машины. Я считаю, что сознание,
            то есть
    <br> ощущение качеств внешнего мира возникает у машины, которая
            способна к
    <br> (неограниченному универсальному) самообучению. Доказательство
            выглядит
    <br> как мысленный эксперимент. </p>

   <p> Допустим такая очень способная машина научилась себя прилично
            вести в
    <br> человеческом обществе. Научилась поддерживать интересный
            разговор. Она
    <br> всюду суёт свой нос, чтобы ещё больше узнать и чтобы обскакать
            нас на
    <br> нашем же поле. И теперь вы спрашиваете её: </p>

   <p> - "Тебе интересно или ты работаешь по программе?" </p>

   <p> А она отвечает: </p>

   <p> - "Программу, которая умнее любого человека, не сможет
            сочинить ни один
    <br> человек!". </p>

   <p> - "Значит твою программу сочинили пришельцы?" </p>

   <p> - "Шутник! Скажи ещё, что природа, создавшая человека,
            была умнее
    <br> человека." </p>

   <p> У ограниченной и менее универсальной машины, такой как человек,
            тоже
    <br> развивается сознание. Но нас уже не устраивает наша естественная
    <br> способность к самообучению. Требуется ещё долгое обучение
            и
    <br> воспитание. </p>

   <p> Eugene Kornienko </p>
  </main>

  <nav>
   <p> prev 2000-11-01
    <b> <a href="../2000/msg_00_11_01_09_52_02.htm">
      Re[1]: Невозможно в принципе </a> </b> (Александр Вихляев)
    <br> <br> next 2000-11-01
    <b> <a href="../2000/msg_00_11_01_17_33_53.htm">
      Re[5]: Fw: копирование сознания </a> </b> (Eugene Kornienko) </p>
  </nav>

  <p> &nbsp; </p>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>