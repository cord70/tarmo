<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Re[5]: Fw: копирование сознания </title>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/tarmo/2000/msg_00_11_01_17_33_53.htm" rel="canonical">
  <link href="https://cord70.github.io/tarmo/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>

   <h1> Re[5]: Fw: копирование сознания </h1>

   <p> From:
    <b> Eugene Kornienko </b> ( korn@online.ru ) Date: 2000-11-01 17:33 </p>

   <p> from: Eugene Kornienko &lt;korn@online.ru &gt;
    <br> newsgroups: fido7.su.philosophy
    <br> date: 26 августа 2000 г. 21:25
    <br> subject: Re: Копирование сознания </p>

   <p> Igor Valerjev &lt;valer@notabene.mtu-net.ru &gt; пишет </p>

   <p> <i> &gt;&gt; находит похожее сочетание в прошлом, после
     <br> &gt;&gt; которого "желательное состояние" достигалось
                лучше.
     <br> &gt; Все равно не очень понятно: что такое "желательное
                состояние"?
     <br> &gt; Каким образом определяется, что желательно, а что -
                нет?
     <br> &gt; Что вообще имеется в виду под "целевой функцией"? </i> </p>

   <p> Это величина, измеряемая сенсорами робота. Работа мозга, как
            творческого
    <br> ядра системы управления, состоит в том, чтобы увеличить
            значение этой
    <br> величины. Смысл "целевой функции" придумывает
            разработчик робота.
    <br> Самому роботу он не известен. </p>

   <p> Допустим, я могу задать эту функцию равной величине заряда
            батарей.
    <br> Тогда поведение робота будет развиваться в таком направлении,
            чтобы при
    <br> любых обстоятельствах батареи оказывались максимально заряженными.
            Ему
    <br> придётся осваивать закономерности окружающего мира, преодолевать
    <br> препятствия, бороться с конкурентами, заискивать перед хозяином,
    <br> выполняя его глупые тесты на интеллект. И всё ради того,
            чтобы
    <br> нормально себя чувствовать, то есть, чтобы чувствовать,
            что батареи
    <br> заряжены. </p>

   <p> Все ощущения робота (зрение, слух и т.п.) развиваются из этого
    <br> первичного чувства как оттенки различных качеств внешнего
            мира, влияющих
    <br> на уровень удовлетворения "основного инстинкта". </p>

   <p> Напомню, чтобы показать, что копирование сознания человека
            не совсем уж
    <br> утопия, я ушёл от темы и привёл пример того, что копирование
            сознания
    <br> удачно устроенного робота технически возможно. При этом
            я немного
    <br> рассказал о конструкции робота, способного к самообучению.
            Важными
    <br> частями этой конструкции являются "абстрактный мозг"
            и "целевая
    <br> функция". Я не утверждаю, что мозг и биологические
            "цели" человека в
    <br> чём-то похожи на эти технические элементы. </p>

   <p> <i> &gt; хотелось бы четче представить общую постановку задачи. </i> </p>

   <p> Если вы говорите о задаче копирования человеческого сознания,
            то для её
    <br> правильной постановки нужно сначала выяснить, </p>

   <p> (1) Что такое сознание, в какой мере к сознанию относятся
            ощущения,
    <br> эмоции и интеллект. </p>

   <p> (2) Почему и как сознание развивается у человека. Какова роль
            мозга,
    <br> нервной системы, обучения, взаимодействия с объективным
            миром. </p>

   <p> (3) Что именно нужно копировать, чтобы получить копию сознания,
    <br> например, в другом теле. </p>

   <p> (4) Возможно ли это технически в принципе. </p>

   <p> Эти вопросы перечислены в таком порядке, что каждый вопрос
            может быть
    <br> решён только после предыдущего. Аргумент о том, что когда
            скорость
    <br> компьютера и объём винчестера станут достаточно велики,
            то вопрос (4)
    <br> будет решён, ничего не стоит без решения первых трёх вопросов. </p>

   <p> Однако все эти вопросы в применении к искусственному чувствующему
    <br> существу, роботу я считаю уже решёнными. И ответ на вопрос
            о копировании
    <br> сознания робота определённой конструкции решается положительно. </p>

   <p> Горбачев Вадим &lt;wadim@integro.ru &gt; пишет </p>

   <p> <i> &gt; Вы легко сваливаетесь к солипсизму и должны будете
                признать, что кроме
     <br> &gt; Вас лично ничего больше в мире нет, а моргание Ваших
                глаз приводит
     <br> &gt; к разрывному существованию мира. Да и Ваше существование
                придется
     <br> &gt; очень сильно думать, как объяснить. </i> </p>

   <p> Солипсизм ничем не хуже прочих измов, принимающих на веру
            первичность
    <br> материи, сознания или Бога. Объяснение происхождения природы
            и
    <br> сознания - задача науки. </p>

   <p> <i> &gt;&gt; Сознательное, ощущающее существо может не иметь
                материального тела
     <br> &gt;&gt; или может иметь много физически не связанных тел.
     <br> &gt; Желательно бы привести примеры. Я подозреваю, что Вы
                самобытно
     <br> &gt; понимаете, что такое есть "сознательное существо". </i> </p>

   <p> Возможно. Первым признаком сознания я считаю ощущение, эмоции,
            а не
    <br> интеллект. </p>

   <p> Существо без материального тела - это Windows. Интеллект у
            него уже
    <br> есть. Когда его сделают чувствующим, он станет сознательным
            существом.
    <br> Существо, имеющее много физически не связанных тел, это
            Интернет. Его
    <br> "тела" связаны информационно. </p>

   <p> <i> &gt; Какой функцией "моделируется" рефлексия?
                А без
     <br> &gt; этого, какое же "сознание"? </i> </p>

   <p> Я не говорю о моделировании. У робота, о котором идёт речь,
            должны
    <br> быть свои ощущения и эмоции (как вы говорите, рефлексия),
            и от него
    <br> нельзя сразу требовать разумного поведения. </p>

   <p> <i> &gt; В первую очередь это касается переноса
     <br> &gt; сознания так, чтобы оно понимало, что осталось его
                "Я",
     <br> &gt; которое помнит о факте согласия на "переселение" </i> </p>

   <p> Переселение сознания робота с сохранением прежних воспоминаний
            возможно.
    <br> Для полноценного переселения сознания человека требуется
            решить
    <br> некоторые проблемы, которые мне кажутся непреодолимыми.
            Однако мне
    <br> понятно, как перенести сознание человека в машину с сохранением
            части
    <br> воспоминаний и с потерей прежнего тела. </p>

   <p> <i> &gt; А кто такой "абстрактный мозг", который
                "не мозг человека"? </i> </p>

   <p> Мозг человека - это сложный орган, большая часть ресурсов
            которого
    <br> расходуется на координацию внутренних систем человека. Природа
            создавала
    <br> мозг путём случайных попыток, и даже не изобрела электрическую
            передачу
    <br> сигналов, что сильно замедляет скорость работы. </p>

   <p> Для возникновения сознания роботу не требуется иметь чего-то
            подобного.
    <br> Достаточно "абстрактного" мозга, который следит
            за тем, какие
    <br> кооперативные действия органов приводят к требуемому состоянию
    <br> организма. Алгоритм проверен на простых примерах, но я ещё
            не подготовил
    <br> его описание на своём сайте. </p>

   <p> <i> &gt; сознание как совокупность материальных полей </i> </p>

   <p> Сознание - это ощущение параметров своего тела и внешнего
            мира. Это
    <br> форма измерения качеств мира. Сознание принадлежит каждому
            субъекту
    <br> порознь. Мои ощущения неизмеримы извне. Никто кроме меня
            не может их
    <br> ощутить или измерить или обнаружить физическим прибором.
            Можно измерить
    <br> только параметры моего тела или мозга. </p>

   <p> Сознание не локализуемо, так как не является физическим объектом.
    <br> К физическому миру относятся только объективная (не зависящая
            от
    <br> сознания) природа. </p>

   <p> <i> &gt; Или Вы считаете, что это получится САМО СОБОЙ после
                того, как
     <br> &gt; Вы навернете больше программ и они волшебным образом
     <br> &gt; самоорганизуются? :) </i> </p>

   <p> Это вопрос о том, у кого и почему возникает сознание. Оно
            возникает у
    <br> определённым образом устроенной машины. Я считаю, что сознание,
            то есть
    <br> ощущение качеств внешнего мира возникает у машины, которая
            способна к
    <br> (неограниченному универсальному) самообучению. Доказательство
            выглядит
    <br> как мысленный эксперимент. </p>

   <p> Допустим такая очень способная машина научилась себя прилично
            вести в
    <br> человеческом обществе. Научилась поддерживать интересный
            разговор. Она
    <br> всюду суёт свой нос, чтобы ещё больше узнать и чтобы обскакать
            нас на
    <br> нашем же поле. И теперь вы спрашиваете её: </p>

   <p> - "Тебе интересно или ты работаешь по программе?" </p>

   <p> А она отвечает: </p>

   <p> - "Программу, которая умнее любого человека, не сможет
            сочинить ни один
    <br> человек!". </p>

   <p> - "Значит твою программу сочинили пришельцы?" </p>

   <p> - "Шутник! Скажи ещё, что природа, создавшая человека,
            была умнее
    <br> человека." </p>

   <p> У ограниченной и менее универсальной машины, такой как человек,
            тоже
    <br> развивается сознание. Но нас уже не устраивает наша естественная
    <br> способность к самообучению. Требуется ещё долгое обучение
            и
    <br> воспитание. </p>

   <p> Eugene Kornienko </p>
  </main>

  <nav>
   <p> prev 2000-11-01
    <b> <a href="../2000/msg_00_11_01_17_21_08.htm">
      Re[2]: Кое-какие идеи </a> </b> (Eugene Kornienko)
    <br> <br> next 2000-11-03
    <b> <a href="../2000/msg_00_11_03_15_56_05.htm">
      Статья м.б. менского о квантовой механике и сознании (сообщение в конференцию) </a> </b> (kovalev) </p>
  </nav>

  <p> &nbsp; </p>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>