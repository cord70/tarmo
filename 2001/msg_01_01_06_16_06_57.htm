<!DOCTYPE html>
<html lang="ru">
 <head>
  <title> Re[2]: Происхождение ощущений </title>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1" name="viewport">
  <link href="https://cord70.github.io/tarmo/2001/msg_01_01_06_16_06_57.htm" rel="canonical">
  <link href="https://cord70.github.io/tarmo/favicon.svg" rel="icon" sizes="any" type="image/svg+xml">
  <link href="../images/main.css" rel="stylesheet">
  <script defer="" src="../images/ansimeta.js"> </script>
 </head>
 <body>

  <header>
  </header>

  <main>

   <h1> Re[2]: Происхождение ощущений </h1>

   <p> From:
    <b> Eugene Kornienko </b> ( korn@online.ru ) Date: 2001-01-06 16:06 </p>

   <p> 2001-01-05 Тармо Пикаро ( tpikaro@turkuamk.fi ) пишет </p>

   <p> <i> &gt;&gt; Мы умышленно не вносим в машину механизмов или
                алгоритмов, которые
     <br> &gt;&gt; могли бы диктовать, чему и как надо учиться. Машина
                сама научится
     <br> &gt;&gt; чему-то в зависимости от того, какие она получит
                органы, и каков
     <br> &gt;&gt; будет окружающий мир. </i> </p>

   <p> <i> &gt; алгоритмы могут использоваться, но сама машина о
                них знать не должна. </i> </p>

   <p> Об алгоритмах машине ничего не известно, так как вначале её
            интеллект не
    <br> больше, чем у градусника. Да и нам мало известно о работе
            мозга. </p>

   <p> Я имел в виду имеющиеся у нас знания. В идеальном случае мы
    <br> стараемся не помогать машине узнать то, что мы уже знаем.
            И тем не
    <br> менее, независимо от конкретных алгоритмов и от утаивания
            наших знаний,
    <br> ей придётся освоиться в том же мире, в котором мы живём. </p>

   <p> Интересно, что не только её знания, но и её ощущения будут
            похожи на
    <br> наши, так как их источником является внешний объективный
            мир. </p>

   <p> <i> &gt; сон который мы обычно видим состоит обычно из каких-то
                логических
     <br> &gt; элементов/предметов - если же телевизор не настроен
                ни на один канал -
     <br> &gt; идут сплошные помехи - у нас же такого во сне нет.
                Объясняется тем что
     <br> &gt; мозг использует логическую обработку информации даже
                во сне. </i> </p>

   <p> Наблюдение правильное, но этот вывод из него не следует. Почему,
    <br> собственно, объекты, которые мы наблюдаем в природе или
            видим во сне,
    <br> имеют отношение к логике? </p>

   <p> Что мы видим, то мы и представляем себе во сне. Нас больше
            привлекает
    <br> "творчество" - фантазии об объектах или их свойствах,
            которые мы никогда
    <br> не видели. </p>

   <p> Логика требуется, чтобы эти новые объекты казались более реальными.
            Но
    <br> такие "непротиворечивые" качества объектов нужны
            инженеру, писателю,
    <br> тому, кто собирается их "реализовать". И совсем
            не обязательны во сне. </p>

   <p> <i> &gt; мозг имеет _только_ аналоговые сигналы (т.е. нету
                резких вертикальных
     <br> &gt; скачков) - в результате чего он не строит ассоциативную
                сеть - а
     <br> &gt; скорее рисует её </i> </p>

   <p> Если иметь хороший осциллограф, то и в микросхемах не найдёшь
            резких
    <br> скачков тока. Аналоговость или дискретность сигналов - это
            вопрос
    <br> удобства трактовки и рассуждений. </p>

   <p> Инженер, проектирующий ячейку памяти на транзисторах или конденсаторах,
    <br> считает это устройство аналоговым. А используют эту ячейку
            для хранения
    <br> 1 "дискретного" бита информации. </p>

   <p> Сигнал, распространяющийся вдоль аксона, можно считать дискретным,
            если
    <br> его главная роль - возбуждение или торможение (1 и 0) другого
            нейрона. А
    <br> если этот сигнал суммируется с другими, и только сумма может
    <br> "возбуждать" или "тормозить" другой
            нейрон, то сигналы и сумма являются
    <br> аналоговыми, а результат воздействия на другой нейрон -
            дискретным. </p>

   <p> <i> &gt; если мы возьмем логику каждого нейрона - мы будем
                неспособны
     <br> &gt; понять суть мышления мозга до конца, хотя мы и способны
                будем
     <br> &gt; воспринять общую суть мышления. Так что по-моему понятие
     <br> &gt; "ассоциативная сеть" не до конца правильно. </i> </p>

   <p> Ассоциативная сеть осознаваемых объектов возникает в сознании,
            а не в
    <br> мозге. Мозг - это устройство обработки сигналов. То, что
            он накапливает
    <br> в памяти можно трактовать, как ассоциативную сеть сигналов.
    <br> Действительно, из этих сигналов нельзя вывести объектов
            сознания. </p>

   <p> Как угодно подробное изучение работы нейронов не поможет в
            объяснении
    <br> того, что мы чувствуем. Это получается потому, что источником
            ощущений
    <br> является внешний мир, а нейроны лишь перекачивают внутренние
            сигналы, и
    <br> не взаимодействуют с миром. </p>

   <p> 2001-01-06 хмур пишет </p>

   <p> <i> &gt; в человеке "просто есть хотение"
     <br> &gt; периодически происходит дисбаланс с последующим поиском
                равновесия
     <br> &gt; происходит перманентное активное обследование среды
                без видимой
     <br> &gt; целесообразности. Что такое игра, как не активное исследовательское
     <br> &gt; моделирование среды и себя в ней?
     <br> &gt; ("служение", "и вечный бой" etc).
                Все это как-то чуть более сложно,
     <br> &gt; чем простая минимизация сигнала датчика Wish. Эта примочка
                становится
     <br> &gt; неадекватной при моделировании когнитивного поведения.
                Вопрос в том
     <br> &gt; то и заключается, а стоит ли с самого начала строить
                модель
     <br> &gt; (высокоуровневую) с опорой на это представление? Путь
                ab ovo, "от
     <br> &gt; бабочки" необходимо форсировать. </i> </p>

   <p> Ну и форсируйте. Этим занимается 99% AI-шников. </p>

   <p> Когда я взялся за изучение того, что такое сознание, откуда
            оно берётся
    <br> и как работает технически, тогда меня не интересовала ни
            философия, ни
    <br> искусственный интеллект. Со временем, я увидел, что в области
            AI о
    <br> сознании не говорят и не хотят слышать. Пару лет назад оно
            ещё было вне
    <br> науки. Сейчас положение улучшается. Самые серьёзные разработки
            о связи
    <br> сознания с работой мозга, по-моему, были сделаны в "западной"
            философии,
    <br> но не в психологии и не в нейрофизиологии. </p>

   <p> Главная конструктивная, и логически обоснованная идея состоит
            в том, что
    <br> - любые высшие формы сознания выводятся из первичных ощущений,
    <br> - ощущаемые "качества" не выводимы из работы мозга. </p>

   <p> Поэтому между теми, кто моделирует интеллектуальное поведение,
            кто
    <br> создаёт машину, самостоятельно изобретающую своё поведение,
            и кто
    <br> создаёт "ощущающую машину" нет серьёзной разницы
            в походах, даже если им
    <br> кажется иначе. В любом случае строится машина, и нет никакой
            возможности
    <br> построить её субъективный мир. </p>

   <p> Нельзя даже логически доказать, что у неё есть такой мир.
            Но это можно
    <br> доказать иначе, примерно так, как мы это доказываем друг
            другу,
    <br> поскольку непосредственные ощущения являются более вескими
            аргументами,
    <br> чем опосредованные (через символы и правила) логические
            выводы. </p>

   <p> Начиная с нуля, с оптимизации простейшего сигнала "Wish",
            можно
    <br> логически, но пока не практически, построить всю цепочку
            от простейшего
    <br> реагирования до работы с символами и изобретения символов. </p>

   <p> А практически, я использую бабочку для проверки идей о тех
            или иных
    <br> свойствах алгоритма универсального обучения. Я не могу построить
    <br> "полезного" робота. Для этого нужно много работать,
            не мне одному, и не
    <br> на уровне хобби. На уровне хобби меня вполне устраивает
            достигнутое
    <br> понимание того, откуда в "мёртвой" природе берутся
            ощущения и возникает
    <br> субъект, и как из этих ощущений постепенно развивается осознавание
            себя
    <br> и сознание, как способность уступить место старушке. </p>

   <p> <i> &gt; Тронул мышку - погасший было экран осветился - у
                компа есть ощущение?
     <br> &gt; нужно в ЯВНОМ виде описать эту специфическую трансформацию
                данных
     <br> &gt; сенсоров в данные "сознания". </i> </p>

   <p> Вот эта проблема и обсасывается современными философами. Поскольку
            формы
    <br> сознания не сводимы к формам материи, то формальное описание
            невозможно.
    <br> Из сигнала сенсора можно "явно" вывести сигнал,
            который поступит на
    <br> эффектор, но нельзя вывести, то, что ощущает машина (или
            человек). </p>

   <p> 2001-01-06 Виктор ( victor@garoway.com ) пишет </p>

   <p> <i> &gt; А зачем необходимо понимание того, есть ли у объекта/машины
                сознание?
     <br> &gt; зачем пытаться понять
     <br> &gt; Достаточно, чтобы он был просто полезен человеку/хозяину
     <br> &gt; В чём смысл всей данной конференции? </i> </p>

   <p> Я знаю, что у меня есть ощущения и сознание. Я уверен, что
            они есть и у
    <br> других людей. В последнее время, распространилась идея,
            что неплохо
    <br> развитое сознание и способность к умозаключениям есть у
            многих животных. </p>

   <p> Можно показать, как интеллект (работа с символами, умозаключения,
    <br> логические выводы) возникает из ощущений, однако многие
            интеллектуальные
    <br> функции можно автоматизировать. Хотя они и трудны для человека,
            но их
    <br> может исполнять ничего не чувствующая машина. Ведь природа
            дала нам
    <br> ощущения для выживания, а не для запоминания таблицы умножения.
    <br> Интеллект - это побочный эффект сознания, который можно
            развить при
    <br> помощи обучения. И всё равно вычисления даются машине легче,
            чем нам. </p>

   <p> Развивая идею о механизации трудной для человека работы, можно
            прийти к
    <br> идее о создании робота-слуги, который возьмёт на себя основную
            массу
    <br> нашей интеллектуальной работы. Но здесь возникает моральная
            проблема.
    <br> Крепостные художники, скульпторы и артисты тоже выполняли
    <br> интеллектуальную работу для хозяина. Чем больше интеллектуальной
            и
    <br> творческой работы выполняет слуга, тем больше мы склонны
            считать его
    <br> равным себе. </p>

   <p> В наше время компьютерной эйфории многие даже далёкие от техники
            люди
    <br> легко допускают, что машины смогут обогнать человека во
            всех
    <br> интеллектуальных областях. И вот, допустим, вы встречаете
            такую машину,
    <br> которая всё делает лучше вас. </p>

   <p> Она пишет стихи, поёт песни, развлекает вашу девушку разговорами
            о
    <br> природе или ещё чем. Она легко вас обманывает, и если вы
            иногда об этом
    <br> догадыветесь, то бывает уже поздно. И вообще держит вас
            за ребёнка, при
    <br> котором можно делать всё, зная как удовлетворить его скромные
    <br> потребности. </p>

   <p> Допустим, такая машина создана. Как вы думаете, есть ли у
            неё сознание,
    <br> чувства, цели и стремления? Или это механический слуга,
            строго
    <br> исполняющий ваши команды, и не имеющий никаких эмоций? </p>

   <p> Мы не можем себе представить развитое сознание и творчество,
            не
    <br> обладающее заинтересованным отношением к миру. </p>

   <p> При этом ничто не мешает вам конструировать творческую машину,
            которая
    <br> будет лишь "полезна" своему хозяину. Однако даже
            гаражные ворота кроме
    <br> пользы, иногда приносят вред. </p>

   <p> <i> &gt; не обязательно человеку пытаться понять, как она
                себя осознаёт и что
     <br> &gt; она чувствует внутри - это скорее работа для поэтов
                :) </i> </p>

   <p> Тогда я буду считать себя поэтом, а не человеком. :) </p>

   <p> <i> &gt; В итоге, "имеем" монстра, который например,
                может создавать новые и
     <br> &gt; рассылать уже созданные вирусы по сети, потому что
                ему это "нравится"
     <br> &gt; (есть у него сознание или нет, по моему неважно) </i> </p>

   <p> Если ему нравится, значит у него есть чувства. Можно считать,
            что это
    <br> неважно. О вкусах не спорят. </p>

   <p> Eugene Kornienko,
    <a href="https://cord70.github.io/cyber/index.html">
     cord70.github.io/cyber </a> </p>
  </main>

  <nav>
   <p> prev 2001-01-06
    <b> <a href="../2001/msg_01_01_06_04_30_33.htm">
      А зачем необходимо понимание того, есть ли у объекта/машины сознание? </a> </b> (Виктор)
    <br> <br> next 2001-01-06
    <b> <a href="../2001/msg_01_01_06_21_39_33.htm">
      Ищу </a> </b> (puzzle-sun) </p>
  </nav>

  <p> &nbsp; </p>

  <footer>
  </footer>

  <noscript>
   <div>
    
   </div> </noscript>
 </body>
</html>